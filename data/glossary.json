[
  {
    "slug": "neural-network",
    "language": "en",
    "term": "Neural Network",
    "category": "Architecture",
    "pronunciation": "/ˈnjʊərəl ˈnetwɜːrk/",
    "definition": "A computational model inspired by biological neural networks, consisting of interconnected nodes (neurons) that process information.",
    "explanation": "A neural network is a machine learning model inspired by the human brain's structure. It consists of layers of interconnected nodes (neurons) that process and transform input data to produce output predictions.\n\n## Architecture\nNeural networks typically have:\n- **Input Layer**: Receives raw data\n- **Hidden Layers**: Process and transform data\n- **Output Layer**: Produces final predictions\n\n## Training\nNetworks learn through backpropagation, adjusting weights to minimize error between predictions and actual outputs.",
    "examples": ["Image classification", "Speech recognition", "Natural language processing"],
    "relatedTerms": ["deep-learning", "backpropagation", "activation-function"]
  },
  {
    "slug": "transformer",
    "language": "en",
    "term": "Transformer",
    "category": "Architecture",
    "pronunciation": "/trænsˈfɔːrmər/",
    "definition": "A neural network architecture based entirely on attention mechanisms, without recurrent or convolutional layers.",
    "explanation": "Transformers revolutionized NLP by processing entire sequences in parallel using self-attention. Key components include multi-head attention, positional encoding, and feed-forward networks. Models like GPT and BERT are based on this architecture.",
    "examples": ["GPT (Generative Pre-trained Transformer)", "BERT (Bidirectional Encoder Representations from Transformers)", "T5 (Text-to-Text Transfer Transformer)"],
    "relatedTerms": ["self-attention", "bert", "gpt"]
  },
  {
    "slug": "deep-learning",
    "language": "en",
    "term": "Deep Learning",
    "category": "Concept",
    "pronunciation": "/diːp ˈlɜːrnɪŋ/",
    "definition": "A subset of machine learning using neural networks with multiple layers to learn hierarchical representations of data.",
    "explanation": "Deep learning models automatically learn features from raw data through multiple layers of abstraction. Each layer learns increasingly complex representations, from simple edges to complex objects. Requires large datasets and computational power.",
    "examples": ["Image classification with CNNs", "Language models like GPT", "Speech recognition systems"],
    "relatedTerms": ["neural-network", "machine-learning", "backpropagation"]
  },
  {
    "slug": "gpt",
    "language": "en",
    "term": "GPT (Generative Pre-trained Transformer)",
    "category": "Model",
    "pronunciation": "/dʒiː piː tiː/",
    "definition": "A family of large language models developed by OpenAI that use transformer architecture for text generation.",
    "explanation": "GPT models are trained on massive text corpora using unsupervised learning, then fine-tuned for specific tasks. They excel at text generation, translation, summarization, and question-answering. GPT-4 is one of the most advanced language models.",
    "examples": ["ChatGPT for conversational AI", "Code generation with GitHub Copilot", "Creative writing assistance"],
    "relatedTerms": ["transformer", "llm", "bert"]
  },
  {
    "slug": "llm",
    "language": "en",
    "term": "LLM (Large Language Model)",
    "category": "Model",
    "pronunciation": "/ɛl ɛl ɛm/",
    "definition": "A neural network with billions of parameters trained on massive text datasets to understand and generate human language.",
    "explanation": "LLMs like GPT-4, Claude, and LLaMA are trained on diverse text from the internet. They demonstrate emergent abilities like reasoning, few-shot learning, and task generalization. Scale is key - larger models show better performance.",
    "examples": ["GPT-4 with 1.76 trillion parameters", "LLaMA 2 for open-source applications", "Claude for long-context understanding"],
    "relatedTerms": ["gpt", "transformer", "fine-tuning"]
  },
  {
    "slug": "backpropagation",
    "language": "en",
    "term": "Backpropagation",
    "category": "Training",
    "pronunciation": "/ˌbækprɒpəˈɡeɪʃən/",
    "definition": "An algorithm for training neural networks by calculating gradients of the loss function with respect to weights.",
    "explanation": "Backpropagation uses the chain rule to efficiently compute gradients layer by layer, from output to input. These gradients guide weight updates during training through gradient descent optimization.",
    "examples": ["Training deep neural networks", "Optimizing convolutional layers", "Fine-tuning language models"],
    "relatedTerms": ["gradient-descent", "neural-network", "loss-function"]
  },
  {
    "slug": "overfitting",
    "language": "en",
    "term": "Overfitting",
    "category": "Concept",
    "pronunciation": "/ˌoʊvərˈfɪtɪŋ/",
    "definition": "When a model learns training data too well, including noise, resulting in poor generalization to new data.",
    "explanation": "Overfitting occurs when models are too complex relative to training data size. Solutions include regularization, dropout, early stopping, and data augmentation. Balance between underfitting and overfitting is crucial.",
    "examples": ["A decision tree memorizing all training examples", "Neural network with too many parameters", "Model performing 100% on training but 60% on test data"],
    "relatedTerms": ["regularization", "dropout", "generalization"]
  },
  {
    "slug": "gradient-descent",
    "language": "en",
    "term": "Gradient Descent",
    "category": "Algorithm",
    "pronunciation": "/ˈɡreɪdiənt dɪˈsɛnt/",
    "definition": "An optimization algorithm that iteratively adjusts parameters to minimize a loss function by following the gradient.",
    "explanation": "Gradient descent updates parameters in the direction opposite to the gradient. Variants include batch, mini-batch, and stochastic gradient descent (SGD). Learning rate controls step size.",
    "examples": ["Training neural network weights", "Optimizing linear regression", "Fine-tuning model parameters"],
    "relatedTerms": ["backpropagation", "optimizer", "learning-rate"]
  },
  {
    "slug": "reinforcement-learning",
    "language": "en",
    "term": "Reinforcement Learning",
    "category": "Paradigm",
    "pronunciation": "/ˌriːɪnˈfɔːrsmənt ˈlɜːrnɪŋ/",
    "definition": "A machine learning paradigm where agents learn by interacting with an environment and receiving rewards or penalties.",
    "explanation": "RL agents learn optimal policies through trial and error. Key concepts include states, actions, rewards, and Q-learning. Used in game playing (AlphaGo), robotics, and autonomous systems.",
    "examples": ["AlphaGo defeating world champions", "Robotic control systems", "Autonomous driving decisions"],
    "relatedTerms": ["q-learning", "policy-gradient", "deep-q-network"]
  },
  {
    "slug": "fine-tuning",
    "language": "en",
    "term": "Fine-tuning",
    "category": "Training",
    "pronunciation": "/faɪn ˈtjuːnɪŋ/",
    "definition": "The process of adapting a pre-trained model to a specific task by continuing training on task-specific data.",
    "explanation": "Fine-tuning leverages transfer learning by starting with pre-trained weights and updating them with smaller learning rates on new data. More efficient than training from scratch.",
    "examples": ["Adapting BERT for sentiment analysis", "Fine-tuning GPT for code generation", "Customizing vision models for medical imaging"],
    "relatedTerms": ["transfer-learning", "pre-training", "llm"]
  },
  {
    "slug": "attention-mechanism",
    "language": "en",
    "term": "Attention Mechanism",
    "category": "Technique",
    "pronunciation": "/əˈtɛnʃən ˈmɛkənɪzəm/",
    "definition": "A technique allowing models to focus on specific parts of the input when producing output.",
    "explanation": "Attention assigns importance weights to different input elements. Used in machine translation, image captioning, and transformers. Enables models to handle long sequences effectively.",
    "examples": ["Focusing on relevant words in translation", "Highlighting important image regions", "Multi-head attention in transformers"],
    "relatedTerms": ["self-attention", "transformer", "encoder-decoder"]
  },
  {
    "slug": "diffusion-models",
    "language": "en",
    "term": "Diffusion Models",
    "category": "Architecture",
    "definition": "Generative models that learn to create data by reversing a gradual noising process.",
    "explanation": "Diffusion models add noise to data incrementally, then learn to denoise. State-of-the-art for image generation (Stable Diffusion, DALL-E). Produce high-quality, diverse outputs.",
    "examples": ["Stable Diffusion for text-to-image", "DALL-E 3 for creative imagery", "Imagen for photorealistic generation"],
    "relatedTerms": ["stable-diffusion", "generative-ai", "gan"]
  },
  {
    "slug": "rag",
    "language": "en",
    "term": "RAG (Retrieval-Augmented Generation)",
    "category": "Technique",
    "pronunciation": "/ræɡ/",
    "definition": "A technique that enhances LLM outputs by retrieving relevant information from external knowledge bases.",
    "explanation": "RAG combines retrieval systems with generative models. First retrieves relevant documents, then uses them as context for generation. Reduces hallucinations and enables knowledge updates without retraining.",
    "examples": ["Question answering with document retrieval", "Customer support chatbots", "Research assistants"],
    "relatedTerms": ["llm", "vector-database", "semantic-search"]
  },
  {
    "slug": "transfer-learning",
    "language": "it",
    "term": "Transfer Learning",
    "category": "Addestramento",
    "definition": "Una tecnica dove la conoscenza appresa da un task viene applicata a un task diverso ma correlato, riducendo tempo di training e requisiti dati.",
    "explanation": "Il transfer learning sfrutta modelli pre-addestrati. Approccio comune: usare un modello addestrato su grande dataset (es. ImageNet) come punto di partenza per task specifico.",
    "examples": ["Usare ResNet pre-addestrato per classificazione immagini mediche", "Fine-tuning di BERT per sentiment analysis", "Adattare GPT per generazione codice"],
    "relatedTerms": ["fine-tuning", "pre-training", "neural-network"]
  },
  {
    "slug": "rete-convoluzionale",
    "language": "it",
    "term": "Rete Convoluzionale",
    "category": "Architettura",
    "pronunciation": "/ˈrete konvolutsjoːnale/",
    "definition": "Una rete convoluzionale è un tipo di rete neurale progettata per elaborare dati strutturati in griglie, come immagini, attraverso l'uso di operazioni di convoluzione.",
    "explanation": "# Rete Convoluzionale\n\n## Introduzione\nLe reti convoluzionali (CNN) sono un'architettura di apprendimento profondo ampiamente utilizzata nel campo della visione artificiale. Queste reti sono particolarmente efficaci nell'estrazione di caratteristiche da dati ad alta dimensione come le immagini.\n\n## Come Funziona\nUna rete convoluzionale è composta da vari strati:\n- **Strati di convoluzione**: Applicano filtri per estrarre caratteristiche\n- **Strati di pooling**: Riducono la dimensionalità mantenendo le caratteristiche più significative\n- **Strati completamente connessi**: Producono le classificazioni finali\n\n## Applicazioni\n- Riconoscimento facciale\n- Classificazione delle immagini\n- Guida autonoma",
    "examples": ["Un sistema di riconoscimento facciale che utilizza una CNN per identificare gli individui in tempo reale.", "Un'applicazione di classificazione delle immagini", "Un software di diagnostica medica che utilizza reti convoluzionali"],
    "relatedTerms": ["rete-neurale", "deep-learning", "visione-artificiale"],
    "etymology": "Il termine 'rete convoluzionale' deriva dalla parola 'convoluzione', un'operazione matematica fondamentale utilizzata per l'estrazione delle caratteristiche nelle reti neurali."
  },
  {
    "slug": "self-attention",
    "language": "it",
    "term": "Self Attention",
    "category": "Tecnica",
    "pronunciation": "/sɛlf əˈtɛnʃən/",
    "definition": "Il self attention è un meccanismo di attenzione utilizzato nei modelli di deep learning che consente a una rete neurale di pesare l'importanza di diverse parti di un input rispetto ad altre.",
    "explanation": "# Self Attention\n\nIl self attention è una tecnica fondamentale nei modelli di linguaggio e visione artificiale. Permette ai modelli di considerare le relazioni tra elementi all'interno di una singola sequenza.\n\n## Come Funziona\n1. **Input**: Set di vettori di input\n2. **Calcolo dei Pesi**: Query, key e value\n3. **Attenzione**: Matrice di attenzione con softmax\n4. **Aggregazione**: Output finale contestuale\n\n## Caratteristiche\n- Contesto dinamico\n- Scalabilità\n- Parallelizzazione\n\n## Applicazioni\n- Traduzione automatica\n- NLP\n- Visione artificiale",
    "examples": ["Un modello di traduzione automatica che utilizza self attention", "Un sistema di raccomandazione", "Un modello di generazione di testo"],
    "relatedTerms": ["transformer", "attention-mechanism", "deep-learning"],
    "etymology": "Il termine 'self attention' deriva dall'idea di attenzione applicata a se stessa, in cui ogni parte di un input può influenzare l'interpretazione di altre parti."
  },
  {
    "slug": "machine-learning",
    "language": "it",
    "term": "Machine Learning",
    "category": "Concetto",
    "definition": "Una branca dell'intelligenza artificiale che permette ai computer di apprendere da dati senza essere esplicitamente programmati.",
    "explanation": "Il machine learning usa algoritmi per identificare pattern nei dati e fare predizioni. Include supervised learning (con etichette), unsupervised learning (senza etichette), e reinforcement learning (con ricompense).",
    "examples": ["Classificazione di email spam", "Raccomandazioni di prodotti", "Riconoscimento vocale"],
    "relatedTerms": ["deep-learning", "supervised-learning", "neural-network"]
  },
  {
    "slug": "bert",
    "language": "it",
    "term": "BERT",
    "category": "Modello",
    "definition": "Bidirectional Encoder Representations from Transformers - un modello di linguaggio pre-addestrato bidirezionale.",
    "explanation": "BERT analizza il testo in entrambe le direzioni per comprendere meglio il contesto. Pre-addestrato su enormi corpus di testo, poi fine-tuned per task specifici come Q&A, sentiment analysis, NER.",
    "examples": ["Google Search per comprendere query complesse", "Analisi del sentiment di recensioni", "Estrazione di entità da testi"],
    "relatedTerms": ["transformer", "gpt", "nlp"]
  },
  {
    "slug": "dropout",
    "language": "it",
    "term": "Dropout",
    "category": "Tecnica",
    "definition": "Una tecnica di regolarizzazione che disattiva casualmente neuroni durante il training per prevenire overfitting.",
    "explanation": "Durante ogni iterazione di training, il dropout rimuove temporaneamente una percentuale casuale di neuroni. Questo forza la rete ad apprendere rappresentazioni più robuste e generalizzabili.",
    "examples": ["Dropout con rate 0.5 in layer densi", "Riduzione overfitting in reti profonde", "Miglioramento generalizzazione"],
    "relatedTerms": ["overfitting", "regularization", "neural-network"]
  },
  {
    "slug": "embedding",
    "language": "it",
    "term": "Embedding",
    "category": "Tecnica",
    "definition": "Una rappresentazione vettoriale densa di entità discrete (parole, immagini) in uno spazio continuo.",
    "explanation": "Gli embedding mappano entità in vettori dove elementi simili sono vicini nello spazio. Word2Vec e GloVe creano word embeddings. Essenziali per NLP e sistemi di raccomandazione.",
    "examples": ["Word2Vec per rappresentare parole", "Embedding di prodotti per raccomandazioni", "Sentence embeddings per similarità semantica"],
    "relatedTerms": ["word2vec", "vector-space", "similarity"]
  },
  {
    "slug": "batch-normalization",
    "language": "it",
    "term": "Batch Normalization",
    "category": "Tecnica",
    "definition": "Una tecnica per normalizzare gli input di ogni layer, stabilizzando e accelerando il training.",
    "explanation": "Batch normalization normalizza le attivazioni usando media e varianza del batch. Riduce internal covariate shift, permette learning rates più alti, e agisce come regolarizzatore.",
    "examples": ["Stabilizzare training di reti profonde", "Accelerare convergenza", "Migliorare performance su vision tasks"],
    "relatedTerms": ["layer-normalization", "deep-learning", "training"]
  },
  {
    "slug": "visione-artificiale",
    "language": "it",
    "term": "Visione Artificiale",
    "category": "Campo",
    "definition": "Un campo dell'AI che permette ai computer di interpretare e comprendere informazioni visive dal mondo.",
    "explanation": "La visione artificiale usa deep learning per analizzare immagini e video. Applicazioni includono riconoscimento oggetti, segmentazione, pose estimation, e autonomous driving.",
    "examples": ["Riconoscimento facciale", "Autonomous driving", "Diagnostica medica da immagini"],
    "relatedTerms": ["rete-convoluzionale", "object-detection", "segmentation"]
  },
  {
    "slug": "nlp",
    "language": "it",
    "term": "NLP (Natural Language Processing)",
    "category": "Campo",
    "definition": "Elaborazione del linguaggio naturale - campo dell'AI che permette ai computer di comprendere e generare linguaggio umano.",
    "explanation": "NLP combina linguistica computazionale e machine learning. Task comuni: sentiment analysis, traduzione automatica, question answering, text generation. Transformers hanno rivoluzionato il campo.",
    "examples": ["ChatGPT per conversazioni", "Google Translate", "Assistenti vocali come Alexa"],
    "relatedTerms": ["transformer", "bert", "gpt"]
  },
  {
    "slug": "ai-generativa",
    "language": "it",
    "term": "AI Generativa",
    "category": "Concetto",
    "definition": "Sistemi di intelligenza artificiale capaci di creare nuovi contenuti originali come testo, immagini, audio, video.",
    "explanation": "L'AI generativa usa modelli come GPT (testo), DALL-E (immagini), Stable Diffusion (immagini). Apprende pattern dai dati di training e genera contenuti nuovi ma realistici.",
    "examples": ["ChatGPT per scrittura creativa", "Midjourney per arte digitale", "Suno per generazione musicale"],
    "relatedTerms": ["gpt", "diffusion-models", "gan"]
  },
  {
    "slug": "cnn",
    "language": "en",
    "term": "CNN (Convolutional Neural Network)",
    "category": "Architecture",
    "pronunciation": "/siː ɛn ɛn/",
    "definition": "A deep learning architecture specialized for processing grid-like data such as images, using convolutional layers.",
    "explanation": "CNNs use convolution operations to automatically learn spatial hierarchies of features. Key components include convolutional layers, pooling layers, and fully connected layers. Revolutionized computer vision.",
    "examples": ["ResNet for image classification", "YOLO for object detection", "U-Net for image segmentation"],
    "relatedTerms": ["convolution", "pooling", "computer-vision"]
  },
  {
    "slug": "gan",
    "language": "en",
    "term": "GAN (Generative Adversarial Network)",
    "category": "Architecture",
    "pronunciation": "/ɡæn/",
    "definition": "A framework where two neural networks compete: a generator creates fake data and a discriminator tries to distinguish real from fake.",
    "explanation": "GANs consist of a generator and discriminator trained adversarially. The generator improves at creating realistic data while the discriminator improves at detection. Used for image generation, style transfer, and data augmentation.",
    "examples": ["StyleGAN for face generation", "CycleGAN for image-to-image translation", "Pix2Pix for paired image translation"],
    "relatedTerms": ["generator", "discriminator", "generative-ai"]
  },
  {
    "slug": "activation-function",
    "language": "en",
    "term": "Activation Function",
    "category": "Concept",
    "pronunciation": "/ˌæktɪˈveɪʃən ˈfʌŋkʃən/",
    "definition": "A mathematical function applied to a neuron's output to introduce non-linearity into the network.",
    "explanation": "Activation functions enable neural networks to learn complex patterns. Common functions include ReLU, sigmoid, tanh, and softmax. They determine whether a neuron should be activated based on input.",
    "examples": ["ReLU for hidden layers", "Sigmoid for binary classification", "Softmax for multi-class classification"],
    "relatedTerms": ["relu", "sigmoid", "neural-network"]
  },
  {
    "slug": "loss-function",
    "language": "en",
    "term": "Loss Function",
    "category": "Concept",
    "pronunciation": "/lɒs ˈfʌŋkʃən/",
    "definition": "A function that measures the difference between predicted and actual values, guiding model optimization.",
    "explanation": "Loss functions quantify model error. Common types include Mean Squared Error (MSE) for regression, Cross-Entropy for classification. Optimization minimizes loss through gradient descent.",
    "examples": ["MSE for regression tasks", "Cross-entropy for classification", "Huber loss for robust regression"],
    "relatedTerms": ["gradient-descent", "optimization", "backpropagation"]
  },
  {
    "slug": "regularization",
    "language": "en",
    "term": "Regularization",
    "category": "Technique",
    "pronunciation": "/ˌrɛɡjʊləraɪˈzeɪʃən/",
    "definition": "Techniques to prevent overfitting by adding constraints or penalties to the model during training.",
    "explanation": "Regularization methods include L1 (Lasso), L2 (Ridge), dropout, and early stopping. They reduce model complexity and improve generalization to new data.",
    "examples": ["L2 regularization in linear regression", "Dropout in neural networks", "Early stopping to prevent overtraining"],
    "relatedTerms": ["overfitting", "dropout", "generalization"]
  },
  {
    "slug": "encoder-decoder",
    "language": "en",
    "term": "Encoder-Decoder",
    "category": "Architecture",
    "pronunciation": "/ɪnˈkoʊdər dɪˈkoʊdər/",
    "definition": "An architecture where an encoder processes input into a representation and a decoder generates output from it.",
    "explanation": "Encoder-decoder architectures are used for sequence-to-sequence tasks. The encoder compresses input into a context vector, the decoder generates output. Common in machine translation and summarization.",
    "examples": ["Seq2Seq for translation", "Transformer encoder-decoder", "VAE (Variational Autoencoder)"],
    "relatedTerms": ["transformer", "sequence-to-sequence", "attention-mechanism"]
  },
  {
    "slug": "tokenization",
    "language": "en",
    "term": "Tokenization",
    "category": "Technique",
    "pronunciation": "/ˌtoʊkənaɪˈzeɪʃən/",
    "definition": "The process of breaking text into smaller units (tokens) like words, subwords, or characters for processing.",
    "explanation": "Tokenization is the first step in NLP pipelines. Methods include word-level, character-level, and subword tokenization (BPE, WordPiece). Balances vocabulary size and representation quality.",
    "examples": ["BPE in GPT models", "WordPiece in BERT", "SentencePiece for multilingual models"],
    "relatedTerms": ["nlp", "bert", "gpt"]
  },
  {
    "slug": "zero-shot-learning",
    "language": "en",
    "term": "Zero-Shot Learning",
    "category": "Concept",
    "pronunciation": "/ˈzɪroʊ ʃɒt ˈlɜːrnɪŋ/",
    "definition": "A model's ability to perform tasks it wasn't explicitly trained on, using only task descriptions or examples.",
    "explanation": "Zero-shot learning leverages pre-trained knowledge to handle new tasks without additional training. Large language models excel at this through prompt engineering.",
    "examples": ["GPT-3 translating to languages not in training", "CLIP matching images to unseen concepts", "ChatGPT solving novel reasoning tasks"],
    "relatedTerms": ["few-shot-learning", "prompt-engineering", "llm"]
  },
  {
    "slug": "prompt-engineering",
    "language": "en",
    "term": "Prompt Engineering",
    "category": "Technique",
    "pronunciation": "/prɒmpt ˌɛndʒɪˈnɪərɪŋ/",
    "definition": "The practice of designing effective text prompts to guide large language models toward desired outputs.",
    "explanation": "Prompt engineering involves crafting instructions, examples, and context to optimize LLM performance. Techniques include few-shot prompting, chain-of-thought, and role-playing.",
    "examples": ["Few-shot prompting with examples", "Chain-of-thought for reasoning", "System prompts for chatbot behavior"],
    "relatedTerms": ["llm", "gpt", "zero-shot-learning"]
  },
  {
    "slug": "rete-neurale",
    "language": "it",
    "term": "Rete Neurale",
    "category": "Architettura",
    "definition": "Un modello computazionale ispirato alle reti neurali biologiche, composto da nodi interconnessi (neuroni) che elaborano informazioni.",
    "explanation": "Le reti neurali sono modelli di machine learning ispirati alla struttura del cervello umano. Consistono di layer di nodi interconnessi che processano e trasformano dati di input per produrre predizioni.",
    "examples": ["Classificazione di immagini", "Riconoscimento vocale", "Elaborazione del linguaggio naturale"],
    "relatedTerms": ["deep-learning", "backpropagation", "activation-function"]
  },
  {
    "slug": "ottimizzazione",
    "language": "it",
    "term": "Ottimizzazione",
    "category": "Concetto",
    "definition": "Il processo di regolazione dei parametri del modello per minimizzare la funzione di loss e migliorare le performance.",
    "explanation": "L'ottimizzazione usa algoritmi come gradient descent, Adam, e RMSprop per aggiornare i pesi del modello. L'obiettivo è trovare i parametri ottimali che minimizzano l'errore di predizione.",
    "examples": ["Adam optimizer per training veloce", "SGD con momentum", "Learning rate scheduling"],
    "relatedTerms": ["gradient-descent", "loss-function", "training"]
  },
  {
    "slug": "data-augmentation",
    "language": "it",
    "term": "Data Augmentation",
    "category": "Tecnica",
    "definition": "Tecniche per aumentare artificialmente la dimensione del dataset di training attraverso trasformazioni dei dati esistenti.",
    "explanation": "Il data augmentation crea variazioni dei dati originali (rotazioni, crop, flip per immagini; sinonimi, back-translation per testo) per migliorare la generalizzazione e ridurre overfitting.",
    "examples": ["Rotazione e flip di immagini", "Sinonimi e parafrasamento per testo", "Noise injection per audio"],
    "relatedTerms": ["overfitting", "training", "generalization"]
  },
  {
    "slug": "pre-training",
    "language": "it",
    "term": "Pre-training",
    "category": "Addestramento",
    "definition": "Il processo di addestrare un modello su un grande dataset generico prima di fine-tuning su task specifici.",
    "explanation": "Il pre-training permette ai modelli di apprendere rappresentazioni generali da grandi quantità di dati non etichettati. Fondamentale per transfer learning e modelli foundation come BERT e GPT.",
    "examples": ["BERT pre-trained su Wikipedia", "GPT pre-trained su web text", "ResNet pre-trained su ImageNet"],
    "relatedTerms": ["fine-tuning", "transfer-learning", "foundation-models"]
  },
  {
    "slug": "tensore",
    "language": "it",
    "term": "Tensore",
    "category": "Concetto",
    "definition": "Una struttura dati multi-dimensionale utilizzata per rappresentare dati in deep learning (scalari, vettori, matrici, tensori n-dimensionali).",
    "explanation": "I tensori sono la struttura dati fondamentale in framework come TensorFlow e PyTorch. Un tensore 0D è uno scalare, 1D è un vettore, 2D è una matrice, e così via.",
    "examples": ["Tensore 2D per immagine grayscale", "Tensore 3D per immagine RGB", "Tensore 4D per batch di immagini"],
    "relatedTerms": ["pytorch", "tensorflow", "array"]
  },
  {
    "slug": "cross-entropy",
    "language": "it",
    "term": "Cross-Entropy",
    "category": "Concetto",
    "definition": "Una funzione di loss comunemente usata per problemi di classificazione che misura la differenza tra distribuzioni di probabilità.",
    "explanation": "La cross-entropy quantifica quanto le predizioni del modello divergono dalle etichette reali. Valori più bassi indicano predizioni migliori. Usata con softmax per classificazione multi-classe.",
    "examples": ["Classificazione di immagini", "Sentiment analysis", "Named Entity Recognition"],
    "relatedTerms": ["loss-function", "softmax", "classification"]
  },
  {
    "slug": "lstm",
    "language": "it",
    "term": "LSTM (Long Short-Term Memory)",
    "category": "Architettura",
    "definition": "Un tipo di rete neurale ricorrente capace di apprendere dipendenze a lungo termine in sequenze temporali.",
    "explanation": "LSTM usa celle di memoria e gate (input, forget, output) per gestire il flusso di informazioni. Risolve il problema del vanishing gradient delle RNN standard. Ora spesso sostituita da Transformer.",
    "examples": ["Previsioni serie temporali", "Generazione di testo", "Riconoscimento vocale"],
    "relatedTerms": ["rnn", "gru", "sequence-modeling"]
  },
  {
    "slug": "batch-size",
    "language": "en",
    "term": "Batch Size",
    "category": "Training",
    "pronunciation": "/bætʃ saɪz/",
    "definition": "The number of training examples used in one iteration of model training.",
    "explanation": "Batch size affects training speed, memory usage, and model convergence. Small batches provide noisier gradients, large batches are more stable but memory-intensive. Common values: 32, 64, 128, 256.",
    "examples": ["Batch size 32 for limited GPU memory", "Batch size 256 for faster training", "Mini-batch gradient descent"],
    "relatedTerms": ["gradient-descent", "training", "optimization"]
  },
  {
    "slug": "learning-rate",
    "language": "en",
    "term": "Learning Rate",
    "category": "Training",
    "pronunciation": "/ˈlɜːrnɪŋ reɪt/",
    "definition": "A hyperparameter controlling how much model weights are updated during training.",
    "explanation": "Learning rate determines the step size in gradient descent. Too high causes instability, too low slows training. Common strategies: fixed, decay, cyclical, adaptive (Adam).",
    "examples": ["Learning rate 0.001 for Adam", "Learning rate decay schedule", "Warm-up then decay strategy"],
    "relatedTerms": ["gradient-descent", "optimization", "hyperparameter"]
  },
  {
    "slug": "epoch",
    "language": "en",
    "term": "Epoch",
    "category": "Training",
    "pronunciation": "/ˈɛpɒk/",
    "definition": "One complete pass through the entire training dataset during model training.",
    "explanation": "Multiple epochs allow the model to learn patterns iteratively. Too few epochs lead to underfitting, too many to overfitting. Monitored with validation loss for early stopping.",
    "examples": ["Training for 100 epochs", "Early stopping at epoch 45", "Learning curves over epochs"],
    "relatedTerms": ["training", "overfitting", "early-stopping"]
  },
  {
    "slug": "feature-extraction",
    "language": "en",
    "term": "Feature Extraction",
    "category": "Technique",
    "pronunciation": "/ˈfiːtʃər ɪkˈstrækʃən/",
    "definition": "The process of transforming raw data into numerical features that machine learning models can process.",
    "explanation": "Feature extraction identifies relevant information from data. In deep learning, this happens automatically through learned representations. Traditional ML requires manual feature engineering.",
    "examples": ["Edge detection in images", "TF-IDF for text", "Convolutional features in CNNs"],
    "relatedTerms": ["feature-engineering", "representation-learning", "cnn"]
  },
  {
    "slug": "computer-vision",
    "language": "en",
    "term": "Computer Vision",
    "category": "Field",
    "pronunciation": "/kəmˈpjuːtər ˈvɪʒən/",
    "definition": "A field of AI enabling computers to derive meaningful information from visual inputs like images and videos.",
    "explanation": "Computer vision tasks include image classification, object detection, segmentation, and pose estimation. Powered by CNNs and transformer-based models like Vision Transformers (ViT).",
    "examples": ["Facial recognition systems", "Autonomous vehicle perception", "Medical image analysis"],
    "relatedTerms": ["cnn", "object-detection", "segmentation"]
  },
  {
    "slug": "object-detection",
    "language": "en",
    "term": "Object Detection",
    "category": "Task",
    "pronunciation": "/ˈɒbdʒɪkt dɪˈtɛkʃən/",
    "definition": "A computer vision task that identifies and localizes objects within an image using bounding boxes.",
    "explanation": "Object detection combines classification and localization. Popular architectures include YOLO (real-time), Faster R-CNN (accurate), and DETR (transformer-based).",
    "examples": ["YOLO for real-time detection", "Faster R-CNN for high accuracy", "Pedestrian detection in autonomous driving"],
    "relatedTerms": ["computer-vision", "cnn", "bounding-box"]
  },
  {
    "slug": "semantic-segmentation",
    "language": "en",
    "term": "Semantic Segmentation",
    "category": "Task",
    "pronunciation": "/sɪˈmæntɪk ˌsɛɡmɛnˈteɪʃən/",
    "definition": "A computer vision task that assigns a class label to every pixel in an image.",
    "explanation": "Semantic segmentation creates dense predictions, useful for understanding scene layout. Common architectures include U-Net, DeepLab, and Mask R-CNN for instance segmentation.",
    "examples": ["Medical image segmentation", "Autonomous driving scene understanding", "Satellite image analysis"],
    "relatedTerms": ["computer-vision", "u-net", "instance-segmentation"]
  },
  {
    "slug": "multimodal",
    "language": "en",
    "term": "Multimodal AI",
    "category": "Concept",
    "pronunciation": "/ˌmʌltɪˈmoʊdəl/",
    "definition": "AI systems that can process and relate information from multiple modalities like text, images, audio, and video.",
    "explanation": "Multimodal models learn joint representations across modalities. Examples include CLIP (vision-language), Flamingo (visual question answering), and GPT-4V (vision understanding).",
    "examples": ["CLIP matching images to text", "GPT-4V describing images", "Image captioning systems"],
    "relatedTerms": ["clip", "vision-language", "cross-modal"]
  },
  {
    "slug": "few-shot-learning",
    "language": "en",
    "term": "Few-Shot Learning",
    "category": "Concept",
    "pronunciation": "/fjuː ʃɒt ˈlɜːrnɪŋ/",
    "definition": "A model's ability to learn from a small number of examples, typically 1-10 examples per class.",
    "explanation": "Few-shot learning leverages pre-trained knowledge and meta-learning. LLMs demonstrate this through in-context learning with examples in the prompt.",
    "examples": ["GPT-3 with 5 examples in prompt", "One-shot image classification", "Meta-learning algorithms"],
    "relatedTerms": ["zero-shot-learning", "meta-learning", "prompt-engineering"]
  },
  {
    "slug": "foundation-model",
    "language": "en",
    "term": "Foundation Model",
    "category": "Concept",
    "pronunciation": "/faʊnˈdeɪʃən ˈmɒdəl/",
    "definition": "Large-scale models trained on broad data that can be adapted to a wide range of downstream tasks.",
    "explanation": "Foundation models like GPT, BERT, and CLIP are pre-trained on massive datasets and fine-tuned for specific applications. They represent a paradigm shift in AI development.",
    "examples": ["GPT-4 as a foundation for many applications", "BERT for NLP tasks", "SAM for image segmentation"],
    "relatedTerms": ["llm", "pre-training", "transfer-learning"]
  },
  {
    "slug": "federated-learning",
    "language": "it",
    "term": "Federated Learning",
    "category": "Paradigma",
    "definition": "Un approccio di machine learning che addestra modelli su dati distribuiti senza centralizzarli, preservando la privacy.",
    "explanation": "Il federated learning permette di addestrare modelli su dispositivi edge (smartphone, ospedali) senza trasferire dati sensibili. Il modello globale aggrega gli aggiornamenti locali.",
    "examples": ["Keyboard prediction su smartphone", "Modelli medici tra ospedali", "Google Gboard"],
    "relatedTerms": ["privacy", "distributed-learning", "edge-computing"]
  },
  {
    "slug": "generazione-linguaggio",
    "language": "it",
    "term": "Generazione del Linguaggio",
    "category": "Task",
    "definition": "Il task di produrre testo coerente e contestualmente appropriato da parte di un modello AI.",
    "explanation": "La generazione del linguaggio usa modelli autoregressivi come GPT che predicono token successivi. Tecniche includono beam search, temperature sampling, e nucleus sampling.",
    "examples": ["ChatGPT che genera risposte", "Completamento automatico", "Summarization"],
    "relatedTerms": ["gpt", "llm", "autoregressive"]
  },
  {
    "slug": "knowledge-distillation",
    "language": "it",
    "term": "Knowledge Distillation",
    "category": "Tecnica",
    "definition": "Tecnica per trasferire conoscenza da un modello grande (teacher) a uno più piccolo (student) mantenendo performance simili.",
    "explanation": "Il knowledge distillation crea modelli compatti che possono girare su dispositivi con risorse limitate. Lo student impara dalle soft predictions del teacher.",
    "examples": ["DistilBERT da BERT", "Modelli mobile da modelli cloud", "Edge deployment"],
    "relatedTerms": ["model-compression", "transfer-learning", "edge-ai"]
  },
  {
    "slug": "attention-heads",
    "language": "it",
    "term": "Multi-Head Attention",
    "category": "Tecnica",
    "definition": "Meccanismo che permette al modello di focalizzarsi su diverse parti dell'input simultaneamente attraverso molteplici teste di attenzione.",
    "explanation": "Il multi-head attention usa più meccanismi di attenzione in parallelo, ognuno che impara pattern diversi. Fondamentale nei Transformer. Tipicamente 8-16 heads.",
    "examples": ["BERT con 12 attention heads", "GPT con 96 heads (large)", "Transformer encoder-decoder"],
    "relatedTerms": ["transformer", "self-attention", "bert"]
  },
  {
    "slug": "residual-connection",
    "language": "it",
    "term": "Residual Connection",
    "category": "Tecnica",
    "definition": "Una connessione skip che permette al gradiente di fluire direttamente attraverso la rete, facilitando il training di reti profonde.",
    "explanation": "Le residual connections (o skip connections) sommano l'input di un layer al suo output. Risolvono il problema del vanishing gradient e permettono reti molto profonde (ResNet).",
    "examples": ["ResNet con 152 layers", "Transformer con residual connections", "U-Net skip connections"],
    "relatedTerms": ["resnet", "vanishing-gradient", "deep-learning"]
  },
  {
    "slug": "layer-normalization",
    "language": "it",
    "term": "Layer Normalization",
    "category": "Tecnica",
    "definition": "Tecnica di normalizzazione che opera su tutti i neuroni in un layer, usata principalmente nei Transformer.",
    "explanation": "Layer normalization normalizza le attivazioni attraverso le features invece che attraverso il batch. Più stabile per sequenze di lunghezza variabile. Usata in GPT e BERT.",
    "examples": ["Layer norm nei Transformer", "GPT pre-norm vs post-norm", "Stabilizzazione training"],
    "relatedTerms": ["batch-normalization", "transformer", "normalization"]
  },
  {
    "slug": "gradient-clipping",
    "language": "it",
    "term": "Gradient Clipping",
    "category": "Tecnica",
    "definition": "Tecnica che limita la magnitudine dei gradienti durante il training per prevenire exploding gradients.",
    "explanation": "Il gradient clipping tronca i gradienti a un valore massimo. Essenziale per addestrare RNN e LSTM. Previene aggiornamenti troppo grandi che destabilizzano il training.",
    "examples": ["Clipping a norma 1.0", "Training LSTM stabili", "Prevenzione gradient explosion"],
    "relatedTerms": ["lstm", "gradient-descent", "training"]
  },
  {
    "slug": "autoregressive",
    "language": "it",
    "term": "Autoregressive Model",
    "category": "Concetto",
    "definition": "Modelli che generano output sequenzialmente, dove ogni elemento dipende da quelli precedenti.",
    "explanation": "I modelli autoregressivi come GPT predicono un token alla volta condizionato sui token precedenti. Usano causal masking per prevenire di vedere il futuro durante il training.",
    "examples": ["GPT per generazione testo", "PixelCNN per immagini", "WaveNet per audio"],
    "relatedTerms": ["gpt", "causal-masking", "generation"]
  }
]
